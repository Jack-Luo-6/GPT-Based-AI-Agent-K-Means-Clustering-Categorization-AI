{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "963cb779",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3705e3cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import replicate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c8bf2492",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Llama2\n",
    "class LLM1():\n",
    "    def __init__(self, api):\n",
    "        #Set the REPLICATE_API_TOKEN environment variable\n",
    "        os.environ[\"REPLICATE_API_TOKEN\"] = api\n",
    "        self.model_version = \"meta/llama-2-70b-chat:02e509c789964a7ea8736978a43525956ef40397be9033abf9fd2badfe68c9e3\"\n",
    "    \n",
    "    def run(self, prompt):\n",
    "        output = replicate.run(\n",
    "            self.model_version,\n",
    "            input={\n",
    "                \"prompt\": prompt\n",
    "            }\n",
    "        )\n",
    "        response = \"\"\n",
    "        for word in output:\n",
    "            response += word\n",
    "        return response\n",
    "\n",
    "\n",
    "api = \"r8_Z3yjMbxweBHOIDzKuDLtCGgkpXlGHmI2yWxXk\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "992eb8be",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jackl\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "# ChatGLM\n",
    "class LLM2():\n",
    "    def __init__(self, address):\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(address, trust_remote_code=True)\n",
    "        self.model = AutoModel.from_pretrained(address, trust_remote_code=True).quantize(4).half().cuda()\n",
    "        self.model = self.model.eval()\n",
    "\n",
    "    def run(self, prompt):\n",
    "        response, history = self.model.chat(self.tokenizer, prompt, history = [])\n",
    "        return response\n",
    "\n",
    "\n",
    "address = \"C:\\\\Users\\\\By Yu\\\\chatglm-6b\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fc9bb082",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Toolkit:\n",
    "    def __init__(self, tools):\n",
    "        # tools is a list of three-tuples of (name, function, description)\n",
    "        # self.tools is a dictionary from names to two tuples of (function, description)\n",
    "        self.tools = {}\n",
    "        for item in tools:\n",
    "            if item[0] in self.tools.keys():\n",
    "                print(\"Tool \\\"{}\\\" already exist.\".format(name))\n",
    "                continue\n",
    "            tools[item[0]] = (item[1], item[2])\n",
    "    \n",
    "    def __str__(self):\n",
    "        string = \"\"\n",
    "        for tool in self.tools.items():\n",
    "            string += tool[0]\n",
    "            string += \": \"\n",
    "            string += tool[1][0].__name__\n",
    "            string += \", \"\n",
    "            string += tool[1][1]\n",
    "            string += '\\n'\n",
    "        return string\n",
    "    \n",
    "    def add_tool(self, new_tool):\n",
    "        name = new_tool[0]\n",
    "        if (name == \"\"):\n",
    "            name = new_tool[1].__name__\n",
    "        if name in self.tools.keys():\n",
    "            print(\"Tool \\\"{}\\\" already exist.\".format(name))\n",
    "            return -1\n",
    "        self.tools[name] = (new_tool[1], new_tool[2])\n",
    "    \n",
    "    def remove_tool(self, name):\n",
    "        if name in self.tools.keys():\n",
    "            return self.tools.pop(name)\n",
    "        else:\n",
    "            print(\"Tool {} not exist.\".format(name))\n",
    "    \n",
    "    def call_tool(self, name, tool_inputs):\n",
    "        if name in self.tools.keys():\n",
    "            return self.tools[name][0](tool_inputs)\n",
    "        else:\n",
    "            print(\"Tool {} not exist.\".format(name))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ad661802",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent:\n",
    "    def __init__(self, pre_prompt, model, toolkit, hyperparameters = {}):\n",
    "        self.pre_prompt = pre_prompt # string, starting lines of the agent, role and purpose\n",
    "        self.model = model # large language model, (supposedly) a class that encapsulates a language model to regulate the interface\n",
    "        self.toolkit = toolkit # a class that manages all the tools and descriptions\n",
    "        self.thought = [] # the current thought, a list is to align with action and observation\n",
    "        self.action = [] # the current action, a list for many tool-callings\n",
    "        self.observation = [] # the current observation, a list for many tool-callings\n",
    "        # memory, a dictionary of previous thoughts, actions and observations\n",
    "        self.memory = {\"thought\": [], \"action\": [], \"observation\": []} # should be linked list\n",
    "        # how many memory to record, weight of each input material\n",
    "        self.hyperparameters = hyperparameters\n",
    "    \n",
    "    def add_tool(self, new_tool):\n",
    "    # add a new tool to toolkit\n",
    "    # tool contains a function and its description\n",
    "    # name is default the function name\n",
    "        Toolkit.add_tool(new_tool)\n",
    "    \n",
    "    def remove_tool(self, name):\n",
    "    # remove an exsisting tool from toolkit by its name\n",
    "    # return the removed tool\n",
    "        return toolkit.remove_tool(name)\n",
    "    \n",
    "    def call_tool(self, name, tool_inputs):\n",
    "    # call a tool by its name and the given inputs\n",
    "        return toolkit.call_tool(name, tool_inputs)\n",
    "    \n",
    "    def generate_prompt(self, inputs):\n",
    "    # generate the prompt based on, pre-prompt, input information, tool descriptions, and memory\n",
    "        prompt = \"\"\n",
    "        return prompt\n",
    "    \n",
    "    def update_memory(self):\n",
    "        self.memory[\"thought\"].append(self.thought)\n",
    "        self.memory[\"action\"].append(self.action)\n",
    "        self.memory[\"observation\"].append(self.observation)\n",
    "        # delete previous memory if too much\n",
    "        for i in range(len(self.memory[\"thought\"]) - self.hyperparameters[\"max_memory_len\"]):\n",
    "            self.memory[\"thought\"].pop(0)\n",
    "            self.memory[\"action\"].pop(0)\n",
    "            self.memory[\"observation\"].pop(0)\n",
    "    \n",
    "    def Thought(self, inputs):\n",
    "    # determine the action based on input information and tool descriptions\n",
    "    # input the prompt to model\n",
    "        prompt = self.generate_prompt(inputs)\n",
    "        response = self.model.run(prompt)\n",
    "        self.thought = []\n",
    "        self.thought.append(response)\n",
    "        new_action = (\"Tool name\", \"Tool input\") # action name and input need to be extracted\n",
    "        self.action = []\n",
    "        self.action.append(new_action)\n",
    "    \n",
    "    def Action(self):\n",
    "    # act on the decision made in thought\n",
    "    # get observation (tool output)\n",
    "        self.observation = []\n",
    "        # self.observation.append(call_tool(self.action[-1][0], self.action[-1][1]))\n",
    "        self.observation.append(\"Tool output\")\n",
    "        \n",
    "    def Observation(self):\n",
    "    # evaluate the observation, from users\n",
    "        return\n",
    "    \n",
    "    def output(self):\n",
    "        string = \"Current storage:\\nThought: \" + self.thought[0]\n",
    "        string += \"\\n\\nAction: \" + self.action[0][0] + \", \" + self.action[0][1]\n",
    "        string += \"\\n\\nObservation: \" + self.observation[0]\n",
    "        return string\n",
    "    \n",
    "    def run(self, inputs):\n",
    "        self.Thought(inputs)\n",
    "        self.Action()\n",
    "        self.Observation()\n",
    "        self.update_memory()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de7f16e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f920fe46",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    api = \"r8_Z3yjMbxweBHOIDzKuDLtCGgkpXlGHmI2yWxXk\"\n",
    "    model = LLM1(api)\n",
    "    tools = [] # a list of three-tuples of (name, function, description)\n",
    "    toolkit = Toolkit(tools)\n",
    "    pre_prompt = \"\"\"xxx\"\"\"\n",
    "    hyperparameters = {\"max_memory_len\": 2, \"prompt_memory_len\": 1}\n",
    "    agent = Agent(pre_prompt, model, toolkit, hyperparameters)\n",
    "    agent.run(\"Testing\")\n",
    "    string = agent.output()\n",
    "    print(string)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4c7ff836",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current storage:\n",
      "Thought:  Hello! I'm happy to assist you in any way I can. Is there something specific you need help with today? Do you have a task or project you'd like me to assist you with, or is there something else I can help you with? Let me know and I'll do my best to be of service!\n",
      "\n",
      "Action: Tool name, Tool input\n",
      "\n",
      "Observation: Tool output\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
